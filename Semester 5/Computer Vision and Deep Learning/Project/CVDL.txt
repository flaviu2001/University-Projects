Literature review section

1. Learning to Cartoonize Using White-box Cartoon Representations
This paper proposes a GAN (Generative Adversarial Network) approach to solving our problem but by also taking into account three main features of the images, namely the surface representation which is the same photo except the fine details between surfaces, basically a blurred version of the photo, the structure of the photo, which is characterised by the clear boundaries of a photo and more sparse colors painting the surfaces. Finally the texture representation is basically the same photo but in greyscale, so that the GAN doesn't concern itself with color at this step, but rather the finer details inside the photo, the color differences will be picked up by the other two features. The GAN framework consists in a generator and two discriminators (one to distinguish between surface representation extracted from model outputs and cartoons and one to distinguish between texture representations from outputs and cartoons).